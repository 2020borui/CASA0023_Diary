[
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html",
    "href": "Wk1_Introduction_to_remote_sensing.html",
    "title": "Introduction to remote sensing",
    "section": "",
    "text": "1.1 Summary\nThis week’s learning content can be divided into two parts: The first part is the concept of remote sensing and the process of gaining the data. Especially, discussing how the interaction between Electromagnetic radiation and Earth’s surface (reflecting, absorbing and scattering) influences the data quality. There are different impacts on electromagnetic radiation with different wavelengths, so it’s important to choose suitable bands to analyse. Moreover, the weather especially the clouds will influence on capturing data. SAR can go through the clouds to reduce the impacts.\nThe second parts introduce the type of remote data, and how to simply deal with data by plotting spectral signatures. In this practical we use snap and r to deal with Landsat and Sentinel data. The main difference between remote data is from four resolutions: spatial, spectral, temporal and radiometric.\nThe steps are:\nTasseled Caps",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#summary",
    "href": "Wk1_Introduction_to_remote_sensing.html#summary",
    "title": "Introduction to remote sensing",
    "section": "",
    "text": "remote sensing process Source: Remote Sensing for Dummies\n\n\n\n\n\n\nDownloading data with less cloud cover, choosing different band combinations for different visuals\n\n\nMasking the study area and resampling the data in one spatial resolution using the nearest neighbour. Choosing down-scaling to avoid errors when calculating. The nearest neighbour is more effective and faster than bilinear or cubic convolution. But there will be abrupt changes at the boundary leading to large errors. When deciding to resample the resolution should not change too much which will influence the accuracy of the result.\n\n\nSelect POIs, and create vector data containers for different land cover.\n\n\nDraw vector, export the Geo-tiff and shapefile load the file in R studio, and extract the value of tiff by vector.\n\n\nPlotting the Spectral signatures and comparing the difference of two sensors with the same band and same land use by t-test. The value of Landsat is much greater than that of Sentinel.\n\n\n\n\n\n\n\n\n\n\n\nLandsat Spectral signatures\n\n\n\n\n\n\n\nSentinel Spectral signatures",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#applications",
    "href": "Wk1_Introduction_to_remote_sensing.html#applications",
    "title": "Introduction to remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nI’m interested in remote sensing in vegetation monitoring. The main difference between the two sensors Landsat and Sentinel is in the various resolutions on spatial, spectral and temporal. By comparing two articles about machine learning used in vegetation monitoring, I observed that two types of data perform differently in different tasks. Sentinel data performs more accurately in predicting by regression on a small scale, the Landsat data is more accurate in classifying vegetation types over large areas.\nIt may be due to the following reasons: Sentinel has a red edge band (B5, B6 and B7) that is more sensitive to monitoring vegetation. It also has a higher resolution of around 10M and 20M, so it has a more accurate prediction of vegetation characteristics such as trunk height for forest variables. (Astola et al. 2019) Sentinel has a 5-day return cycle, so, it captures short-term changes in vegetation well, but it will be complicated to handle large ranges of data. As a new sensor from 2015, it may be a lack of data build-up.\n\n\n\nModel accuracy for different data sources Source: Ram C. Sharma’s article\n\n\nTo my surprise, Landsat data are more accurate in studies related to the classification of vegetation types by setting a random forest model. (Sharma, Hara, and Tateishi 2017)Although Landsat has a 16-day return cycle, due to the length of time covered it has rich datasets and it has SWIR and thermal infrared bands, both of which can provide help for the study of large-scale classification. At the end of the article, the author got a more precise classification by combination of the two types of data.\nHow can these methods be applied to real life? Scientists found that near-infrared radiation can observe the health of vegetation. It is based on the principle that the health status of plants will influence the plant’s spectrum of both absorption and reflection. The U.S. Department of Agriculture uses Landsat and the U.S. Geological Survey to forecast agricultural productivity in each growing season. () According to the comparison above, I think the result will be better to use Landsat data for large-scale farmland species identification, and then use Sentinel data to monitor small-scale changes in the growing season of a single crop.\n\n\n\nThe difference between Sentinel-2 and Landsat 8\n\n\nComparison Factors\nSentinel-2\nLandsat 8\n\n\n\n\nTemporal Coverage\n~73 times/year (high frequency)\n~23 times/year (low frequency)\n\n\nSpatial Resolution\n10 m (selected bands), 20 m (red edge)\n30 m (except 15 m panchromatic)\n\n\nBand Configuration\nVisible, NIR, SWIR, red edge (no thermal infrared)\nVisible, NIR, SWIR, thermal infrared\n\n\nClassification Performance\nMulti-temporal features enhance vegetation health classification\nLong-term data improves stability, versatile band coverage\n\n\nAdvantages\nSuperior for small-scale, short-term changes (e.g., vegetation health)\nSuperior for large-scale, long-term changes (e.g., vegetation types)\n\n\nApplications\nBetter for specific feature prediction\nBetter for large-scale classification",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "href": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "title": "Introduction to remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThrough this week I have learnt about the principles of remote sensing and a deep understanding of the advantages and application of Sentinel-2 and Landsat 8 data. Considering that radiation is an important element in remote sensing, I am wondering how climate change affects remote sensing vegetation monitoring. With global warming and the greenhouse effect, will the increased thermal radiation in the atmosphere have impacts on remote sensing results? Will the increased plant transpiration due to warming affect the absorption of red light and the reflection of near-infrared light? Can remote sensing capture the slight changes? Whether the use of thermal infrared bands in vegetation health monitoring needs to be adapted due to global warming? These issues need to be addressed step by step in the future.\nAlthough there are massive studies about using and comparing Landsat and Sentinel-2 data on vegetation research, I am interested in how to innovate under the background of climate change. Could we build a model to predict the influence of climate on vegetation growth? Based on that we can predict how vegetation in a region or globally will be distributed over the next 50 years based on current climate change. It’s a big help to our food security and species conservation. Moreover, through this week’s studying, I also learned how to choose data with suitable resolution and choose a band which is more suitable for specific tasks. I think the ability to choose suitable data sets and methods is important in future study and learning.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017. “High-Resolution Vegetation Mapping in Japan by Combining Sentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine Learning and Cross-Validation Approach.” Land 6 (3): 50. https://doi.org/10.3390/land6030050.",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html",
    "href": "Wk3_Corrections.html",
    "title": "Corrections",
    "section": "",
    "text": "1.1 Summary\nThe lecture includes two parts: Correction data and Accessing data. This is preparation for conducting data research.",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "Wk4_Policy.html",
    "href": "Wk4_Policy.html",
    "title": "Policy",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Astola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma\nKilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for\nForest Variable Prediction in Boreal Region.” Remote Sensing\nof Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017.\n“High-Resolution Vegetation Mapping in Japan by Combining\nSentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine\nLearning and Cross-Validation Approach.” Land 6 (3): 50.\nhttps://doi.org/10.3390/land6030050.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Personal Introduction\nMy name is Borui. I am from Beijing. I did my undergraduate degree at China Agricultural University and majored in Landscape Architecture. During that time, I became interested in landscape design, which covered topics such as food security, climate change, urban segregation, etc. This is my portfolio from undergrad. I am also interested in the challenges that cities will face due to climate change, such as flooding, and chose a related topic for my undergraduate final project.\nNow, I am studying MSc in spatial data science. I hope to be able to analyse the problems in urban space using data sciences and to improve my quantitative analysis and coding skills.\nI took this module Remotely Sensing Cities and Environments to learn more about environmental hazards arising from a changing climate. Through learning and operationalising remotely sensed Earth observation data, I hope I can provide effective recommendations for today’s cities or urban planning.\nThis diary will record my learning process throughout the module. It includes a summary of knowledge from each lesson, practical application and personal reflective thinking. I hope to be able to show what I have learnt from this module in this way.",
    "crumbs": [
      "Personal Introduction"
    ]
  },
  {
    "objectID": "Wk2_Presentation.html",
    "href": "Wk2_Presentation.html",
    "title": "Xaringan Presentation",
    "section": "",
    "text": "This week we tried to use markdown tools like Xaringan and Quarto to show our idea on the website with code. How to adjust the templates and hide the code blocks was difficult for me during the learning process. Creating presentations through code gives the presentation file greater presentational reproducibility and flexibility. Although the process of learning is difficult, it can give me a strong sense of achievement. Here is a presentation that introduces the functions of the Sentinel-2, created through the Xaringan.\n\n\n\n\n\n\n\n\nView Full PowerPoint",
    "crumbs": [
      "Xaringan Presentation"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#summary",
    "href": "Wk3_Corrections.html#summary",
    "title": "Corrections",
    "section": "",
    "text": "1.1.1 correction\nThe correction makes the raw remote-sensing data become “Analysis Ready Data”(ARD). In this lecture, we mainly learn four kinds of correction: Geometric Correction, Atmospheric Correction, Orthorectification and Radiometric Correction. I try to figure out the connection between them to have a better understanding. It seems like the Radiometric correction and atmospheric correction are the most common correction steps in remote sensing data processing, and are usually required for every image. Geometric Correction and Orthorectification are commonly used processing scenarios where spatial aberrations exist or where accurate spatial analysis is required, not every data is needed. The following table will introduce details about different corrections. Regression is important in correction methods.\nSurface reflectance is the result of radiative and atmospheric corrections. In practice, we get the reflectance from DN (level 1) through DOS methods. Nowadays there are many ways to get processed data like Landsat8(level 2-surface reflectance). This data has been atmospherically corrected. Saves a lot of work. But in the future, there will be some chance to handle high-resolution images that are not processed. It is still important to know how to correct it and how to tackle problems like aberrations. We should download the data that fits our needs. Using Landsat data as an example, the hierarchical structure of Landsat data is Collection→ Level→ Tier. In general, we choose Collection 2 + Level-2 + Tier 1.\n\n\n\n\n\nCorrection\npurposes /defination\nmethods\ninput data\noutput\nApplications\n\n\n\n\nGeometric Correction\nCorrects distortions caused by the sensor or satellites to align the image with the geographic coordinate system, ensuring spatial accuracy.\ndifferent transformation types(linear, polynomial, Helmert…)\nPixel coordinates of the original image, GCPs（Ground Control Points, Pixel coordinates of the rectified (gold standard) map |\norrected image |\nhe basis for subsequent georectification and Orthorectification |\n\n\nAtmospheric Correction\nRemoval of environmental attenuation:Atmospheric scattering and Topographic attenuation\nDOS（Dark object subtraction, PIFs (Psuedo-invariant Features), Py6S, FLAASH, ACORN, QUAC, ATCOR Empirical Line Correction\n|radiance reflected above the surface , Atmospheric attenuation\n|Top-of-atmosphere reflectance and Surface reflectance\n|Biophysical parameters required and the use of spectral signatures across time and space.\n\n\nOrthorectification\nremoving distortions. making the pixels viewed at the nadir (straight down)\nCosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nradiance, Sun's zenith angle, Sun's incidence angle slope angle (from DEM), slope aspect, solar zenith, solar azimuth\n|geographically aligned and topography removed\n|Orthorectification Is a subset of georectification, useful for Precise Georeferencing and High-Precision Measurement and Spatial Analysi\n\n\nRadiometric Calibration\nConverts the digital value (DN) of an image into a physical sense of radiant brightness or reflectance, eliminating the effects of sensors, light sources, etc.\nLλ = Bias + (Gain * DN)\nDN, sensor information, Solar radiation information\nCorrected image\nOften used as a first step in data pre-processing to provide a basis for subsequent atmospheric corrections, etc.\n\n\n\n\n\n\n\n\n\n1.1.2 Joining the data\nIn some cases, we need to merge the images from different regions and times to cover the study area. We had better choose the image from the same day or else we need to standardise data. In remote sensing, it is called “Mosaicking”. This involves complex arithmetic processes: histogram matching algorithm feathering and blending. But it is simple in R just needs some time.\n\nm1 &lt;- terra::mosaic(l83, l84, fun=\"mean\")\n\n\n\n1.1.3 Image Enhancement\nWe choose the appropriate data, process it, and modify it to generate the desired output. The methods help us change the image and produce the output for our purpose. The methods are as follows.\n\n\n\n\n\nEnhancement\npurposes /defination\nmethods\ninput data\nAdvantages\nApplicable scenarios\n\n\n\n\nContrast Enhancement\nImproved visualisation of the image by widening the distribution of pixel values.\nMinimum - Maximum Percentage Linear and Standard Deviation Piecewise Linear Contrast Stretch\n|Images with a narrow distribution\n|Enhanced image contrast and details\n|pre-processing for subsequent classification and visual interpretation\n\n\nBand Ratioing\nUsing the ratio of reflectance of different bands to highlight specific feature characteristics\ndivision operations (like NDVI, NDBI, tasselled cap etc.)\nMulti-spectral imagery\nEmphasis on relative differences in expression of feature characteristics\nNormalized Burn Ratio\\The Normalised Difference Vegetation Index\\ the Normalized Difference Moisture Index (NDMI)\n\n\nFiltering\nSuppressing noise or highlighting local variations through filter operations.\nLow pass or low frequency (averages the surrounding pixels)/High pass or high frequency - enhance local variations\nOriginal data\nSmooth or sharpen images; extract edge information as required\nFeature extraction, target detection\n\n\nPCA\nDimensionality reduction, removal of inter-band correlations, and extraction of most of the information in the image.\nIn R this is prcomp() from the terra package\nMulti-spectral imagery\nExtracting the main direction of change reduces the computational burden and noise reduction\nData compression, change detection, feature extraction\n\n\nTexture\nmeasuring the relationships between pixel-to-pixel, quantifying roughness to obtain feature characteristics.\nGLCM(Gray Level Co-occurrence Matrix ) second-order texture measures/ third-order texture measures\n|Grey-scale images or single-band data, window\n|Characterisation of feature texture, feature classification, target identification\n|Land cover classification, target detection, environmental monitoring\n\n\nFusion\nFusion of data from different sensors or different times\nPan-sharpening、Gram-Schmidt、IHS |M\nlti-temporal, multi-sensor data |e\nhance the details of the images |H\ngh resolution data generate、changes detection、data integration |",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#application",
    "href": "Wk3_Corrections.html#application",
    "title": "Corrections",
    "section": "1.2 Application",
    "text": "1.2 Application\nDue to there are few works that we need to correct by ourselves in the current stage, I will pay more attention to image enhancement. To my surprise, I have discussed a lot about ratios in the last two weeks due to my strong interest in different band groups, it is also the most simple part of enhancement in my view. So this week, I’d like to analyse the application of texture. Texture has better identification of the inner edges of the image. Firstly, I treat texture as independent of other image enhancements. After reading relevant articles, I recognise texture is usually used with other methods. In common for identifying feature characteristics, texture usually data fusion with multi-spectral images. (Urban) It Helps improve identification accuracy. Textured images are related to the use of different texture metrics, window sizes and bands. In the GLCM package in R, there are lots of texture measures. Different combinations are suitable for identifying different landscapes.\nHow to choose these variables? Hall-Beyer uses PCA to identify key measures that can be directly selected in feature recognition. Generally choosing Mean, in the case of containing edge-like features, choosing CON.COR, for more detailed texture studies, add Ent. These guidelines help me to choose suitable measures. Texture current applies to natural landscape identification such as forests. () But I think it can also used in small-scale urban identification because Ent is sensitive to unnatural edges and can be used to identify artificial landscapes. What’s more, compared with popular Spectroscopic methods, Texture methods (e.g. GLCM) focus on the spatial pattern of the image and may reduce the band radiometric errors due to temperature variation caused by the city heat island effect. But texture can only be used for enlarged objects due to its large computation, which makes it a big limitation to assist other methods in many cases. Especially, The edges of the city are very complex.",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#reflection",
    "href": "Wk3_Corrections.html#reflection",
    "title": "Corrections",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThis week we learned Correction, Mosaicking and image enhancement. We usually comprehend different methods and concepts separately during the learning process. (But the content this week is still hard for me.) But in practice, for different bands and spatial resolutions, the effects of the different methods are also different, so it is necessary to combine various methods. For example, when doing principal component analysis (PCA) on spectral data, the subsequent eigenchannels usually represent indexes like NDVI (vegetation) mentioned in the band ratio. This suggests that there may be a relationship of complementarity between the different approaches. In addition, in order to get more clearer images and results, researchers often combine different sensor data and methods of analysis.\nI realize that innovations don’t have to be just coming up with new approaches. In many cases, integrating, and regrouping existing methods, and applying them to new objects is also an important innovative way for research. That’s why although the data we deal with is already corrected we still need to learn the details about corrections. Researchers need to have an in-depth understanding of the data source and character and the scenarios for the application of various data correction and processing methods. Only based on a full knowledge of these can reasonable analyses and judgments be made. That’s why this week we need to Learning the formulas and principles of the method of correction.",
    "crumbs": [
      "Corrections"
    ]
  }
]