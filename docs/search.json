[
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html",
    "href": "Wk1_Introduction_to_remote_sensing.html",
    "title": "1  Introduction to remote sensing",
    "section": "",
    "text": "1.1 Summary\nThis week’s learning content can be divided into two parts: The first part is the concept of remote sensing and the process of gaining the data. Especially, discussing how the interaction between Electromagnetic radiation and Earth’s surface (reflecting, absorbing and scattering) influences the data quality. There are different impacts on electromagnetic radiation with different wavelengths, so it’s important to choose suitable bands to analyse. Moreover, the weather especially the clouds will influence on capturing data. SAR can go through the clouds to reduce the impacts.\nThe second parts introduce the type of remote data, and how to simply deal with data by plotting spectral signatures. In this practical we use snap and r to deal with Landsat and Sentinel data. The main difference between remote data is from four resolutions: spatial, spectral, temporal and radiometric.\nThe steps are:\nTasseled Caps",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to remote sensing</span>"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#summary",
    "href": "Wk1_Introduction_to_remote_sensing.html#summary",
    "title": "1  Introduction to remote sensing",
    "section": "",
    "text": "remote sensing process Source: Remote Sensing for Dummies\n\n\n\n\n\n\nDownloading data with less cloud cover, choosing different band combinations for different visuals\n\n\nMasking the study area and resampling the data in one spatial resolution using the nearest neighbour. Choosing down-scaling to avoid errors when calculating. The nearest neighbour is more effective and faster than bilinear or cubic convolution. But there will be abrupt changes at the boundary leading to large errors. When deciding to resample the resolution should not change too much which will influence the accuracy of the result.\n\n\nSelect POIs, and create vector data containers for different land cover.\n\n\nDraw vector, export the Geo-tiff and shapefile load the file in R studio, and extract the value of tiff by vector.\n\n\nPlotting the Spectral signatures and comparing the difference of two sensors with the same band and same land use by t-test. The value of Landsat is much greater than that of Sentinel.\n\n\n\n\n\n\n\n\n\n\n\nLandsat Spectral signatures\n\n\n\n\n\n\n\nSentinel Spectral signatures",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to remote sensing</span>"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#applications",
    "href": "Wk1_Introduction_to_remote_sensing.html#applications",
    "title": "1  Introduction to remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nI’m interested in remote sensing in vegetation monitoring. The main difference between the two sensors Landsat and Sentinel is in the various resolutions on spatial, spectral and temporal. By comparing two articles about machine learning used in vegetation monitoring, I observed that two types of data perform differently in different tasks. Sentinel data performs more accurately in predicting by regression on a small scale, the Landsat data is more accurate in classifying vegetation types over large areas.\nIt may be due to the following reasons: Sentinel has a red edge band (B5, B6 and B7) that is more sensitive to monitoring vegetation. It also has a higher resolution of around 10M and 20M, so it has a more accurate prediction of vegetation characteristics such as trunk height for forest variables. (Astola et al. 2019) Sentinel has a 5-day return cycle, so, it captures short-term changes in vegetation well, but it will be complicated to handle large ranges of data. As a new sensor from 2015, it may be a lack of data build-up.\n\n\n\nModel accuracy for different data sources Source: Ram C. Sharma’s article\n\n\nTo my surprise, Landsat data are more accurate in studies related to the classification of vegetation types by setting a random forest model. (Sharma, Hara, and Tateishi 2017)Although Landsat has a 16-day return cycle, due to the length of time covered it has rich datasets and it has SWIR and thermal infrared bands, both of which can provide help for the study of large-scale classification. At the end of the article, the author got a more precise classification by combination of the two types of data.\nHow can these methods be applied to real life? Scientists found that near-infrared radiation can observe the health of vegetation. It is based on the principle that the health status of plants will influence the plant’s spectrum of both absorption and reflection. The U.S. Department of Agriculture uses Landsat and the U.S. Geological Survey to forecast agricultural productivity in each growing season. (Blickensdörfer et al. 2022)According to the comparison above, I think the result will be better to use Landsat data for large-scale farmland species identification, and then use Sentinel data to monitor small-scale changes in the growing season of a single crop.\n\n\n\nThe difference between Sentinel-2 and Landsat 8\n\n\nComparison Factors\nSentinel-2\nLandsat 8\n\n\n\n\nTemporal Coverage\n~73 times/year (high frequency)\n~23 times/year (low frequency)\n\n\nSpatial Resolution\n10 m (selected bands), 20 m (red edge)\n30 m (except 15 m panchromatic)\n\n\nBand Configuration\nVisible, NIR, SWIR, red edge (no thermal infrared)\nVisible, NIR, SWIR, thermal infrared\n\n\nClassification Performance\nMulti-temporal features enhance vegetation health classification\nLong-term data improves stability, versatile band coverage\n\n\nAdvantages\nSuperior for small-scale, short-term changes (e.g., vegetation health)\nSuperior for large-scale, long-term changes (e.g., vegetation types)\n\n\nApplications\nBetter for specific feature prediction\nBetter for large-scale classification",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to remote sensing</span>"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "href": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "title": "1  Introduction to remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThrough this week I have learnt about the principles of remote sensing and a deep understanding of the advantages and application of Sentinel-2 and Landsat 8 data. Considering that radiation is an important element in remote sensing, I am wondering how climate change affects remote sensing vegetation monitoring. With global warming and the greenhouse effect, will the increased thermal radiation in the atmosphere have impacts on remote sensing results? Will the increased plant transpiration due to warming affect the absorption of red light and the reflection of near-infrared light? Can remote sensing capture the slight changes? Does the use of thermal infrared bands in vegetation health monitoring need to be adapted due to global warming? These issues need to be addressed step by step in the future.\nAlthough there are massive studies about using and comparing Landsat and Sentinel-2 data on vegetation research, I am interested in how to innovate under the background of climate change. Could we build a model to predict the influence of climate on vegetation growth? Based on that we can predict how vegetation in a region or globally will be distributed over the next 50 years based on current climate change. It’s a big help to our food security and species conservation. Moreover, through this week’s studying, I also learned how to choose data with suitable resolution and choose a band which is more suitable for specific tasks. I think the ability to choose suitable data sets and methods is important in future study and learning.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nBlickensdörfer, Lukas, Marcel Schwieder, Dirk Pflugmacher, Claas Nendel, Stefan Erasmi, and Patrick Hostert. 2022. “Mapping of Crop Types and Crop Sequences with Combined Time Series of Sentinel-1, Sentinel-2 and Landsat 8 Data for Germany.” Remote Sensing of Environment 269 (February): 112831. https://doi.org/10.1016/j.rse.2021.112831.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017. “High-Resolution Vegetation Mapping in Japan by Combining Sentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine Learning and Cross-Validation Approach.” Land 6 (3): 50. https://doi.org/10.3390/land6030050.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to remote sensing</span>"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html",
    "href": "Wk3_Corrections.html",
    "title": "3  Corrections and Enhancement",
    "section": "",
    "text": "3.1 Summary\nThe lecture includes two parts: Correction data and Accessing data. This is preparation for conducting data research.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "Wk4_Policy.html",
    "href": "Wk4_Policy.html",
    "title": "4  Policy",
    "section": "",
    "text": "4.1 Summary\nNow, we are against the challenges of a changing climate. Disaster risk reduction (DRR) and sustainable development are important for all cities worldwide. The increase in large-scale precipitation, coastal flooding and rising sea levels from climate change is a great challenge to the safety of urban residents and urban infrastructure. According to the projections from NPCC, at the end of the century, the frequency of 100-year floods will be up to 3.6%.\nNew York as a famous coastal city has hundreds of miles of waterfront and commercial harbours. It will face more emergency crises from flooding, the sea levels rise in New York are twice the global average. By the 2050s, nearly 1 million residents will be influenced by the coastal floodings, some commercial regions will be flooded without protective measures. (Fuleihan et al., n.d.)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Astola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma\nKilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for\nForest Variable Prediction in Boreal Region.” Remote Sensing\nof Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nBlickensdörfer, Lukas, Marcel Schwieder, Dirk Pflugmacher, Claas Nendel,\nStefan Erasmi, and Patrick Hostert. 2022. “Mapping of Crop Types\nand Crop Sequences with Combined Time Series of Sentinel-1, Sentinel-2\nand Landsat 8 Data for Germany.” Remote Sensing of\nEnvironment 269 (February): 112831. https://doi.org/10.1016/j.rse.2021.112831.\n\n\nCohen, Sagy, Austin Raney, Dinuke Munasinghe, J. Derek Loftis, Andrew\nMolthan, Jordan Bell, Laura Rogers, et al. 2019. “The Floodwater\nDepth Estimation Tool (FwDET V2.0) for Improved Remote Sensing Analysis\nof Coastal Flooding.” Natural Hazards and Earth System\nSciences 19 (9): 2053–65. https://doi.org/10.5194/nhess-19-2053-2019.\n\n\nFuleihan, Dean, Dominic Williams, Daniel A Zarrilli, and OneNYC\nDirector. n.d. “The City of New York Mayor Bill de Blasio.”\n\n\nHall-Beyer, Mryka. 2017a. “Practical Guidelines for Choosing GLCM\nTextures to Use in Landscape Classification Tasks over a Range of\nModerate Spatial Scales.” International Journal of Remote\nSensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\n———. 2017b. “Practical Guidelines for Choosing GLCM Textures to\nUse in Landscape Classification Tasks over a Range of Moderate Spatial\nScales.” International Journal of Remote Sensing 38 (5):\n1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\nMason, David C., Sarah L. Dance, and Hannah L. Cloke. 2023.\n“Toward Improved Urban Flood Detection Using Sentinel-1:\nDependence of the Ratio of Post- to Preflood Double Scattering Cross\nSections on Building Orientation.” Journal of Applied Remote\nSensing 17 (1): 16507. https://doi.org/10.1117/1.JRS.17.016507.\n\n\n“NYS Flood Impact Decision Support System - FIDSS.” n.d. https://sedac.ciesin.columbia.edu/mapping/nysfidss/?page=NYS-FIDSS&views=About.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017.\n“High-Resolution Vegetation Mapping in Japan by Combining\nSentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine\nLearning and Cross-Validation Approach.” Land 6 (3): 50.\nhttps://doi.org/10.3390/land6030050.\n\n\nTabib Mahmoudi, Fatemeh, Alireza Arabsaeedi, and Seyed Kazem Alavipanah.\n2019. “Feature-Level Fusion of Landsat 8 Data and SAR Texture\nImages for Urban Land Cover Classification.” Journal of the\nIndian Society of Remote Sensing 47 (3): 479–85. https://doi.org/10.1007/s12524-018-0914-8.\n\n\n“THE 17 GOALS | Sustainable Development.” n.d. https://sdgs.un.org/goals.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Personal Introduction\nMy name is Borui. I am from Beijing. I did my undergraduate degree at China Agricultural University and majored in Landscape Architecture. During that time, I became interested in landscape design, which covered topics such as food security, climate change, urban segregation, etc. This is my portfolio from undergrad. I am also interested in the challenges that cities will face due to climate change, such as flooding, and chose a related topic for my undergraduate final project.\nNow, I am studying MSc in spatial data science. I hope to be able to analyse the problems in urban space using data sciences and to improve my quantitative analysis and coding skills.\nI took this module Remotely Sensing Cities and Environments to learn more about environmental hazards arising from a changing climate. Through learning and operationalising remotely sensed Earth observation data, I hope I can provide effective recommendations for today’s cities or urban planning.\nThis diary will record my learning process throughout the module. It includes a summary of knowledge from each lesson, practical application and personal reflective thinking. I hope to be able to show what I have learnt from this module in this way.",
    "crumbs": [
      "Personal Introduction"
    ]
  },
  {
    "objectID": "Wk2_Presentation.html",
    "href": "Wk2_Presentation.html",
    "title": "2  Xaringan Presentation",
    "section": "",
    "text": "This week we tried to use markdown tools like Xaringan and Quarto to show our idea on the website with code. How to adjust the templates and hide the code blocks was difficult for me during the learning process. Creating presentations through code gives the presentation file greater presentational reproducibility and flexibility. Although the process of learning is difficult, it can give me a strong sense of achievement. Here is a presentation that introduces the functions of the Sentinel-2, created through the Xaringan.\n\n\n\n\n\n\n\n\nView Full PowerPoint",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Xaringan Presentation</span>"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#summary",
    "href": "Wk3_Corrections.html#summary",
    "title": "3  Corrections and Enhancement",
    "section": "",
    "text": "3.1.1 Correction\nThe correction makes the raw remote-sensing data become “Analysis Ready Data”(ARD). In this lecture, we mainly learn four kinds of correction: Geometric Correction, Atmospheric Correction, Orthorectification, and Radiometric Correction. I try to figure out the connection between them to have a better understanding. It seems like the Radiometric correction and atmospheric correction are the most common correction steps in remote sensing data processing, and are usually required for every image. Geometric Correction and Orthorectification are commonly used processing scenarios where spatial aberrations exist or where accurate spatial analysis is required, not every data is needed. The following table will introduce details about different corrections. Regression is important in correction methods.\nSurface reflectance is the result of radiative and atmospheric corrections. In practice, we get the reflectance from DN (level 1) through DOS methods. Nowadays there are many ways to get processed data like Landsat8 (level 2-surface reflectance). This data has been atmospherically corrected. Saves a lot of work. But in the future, there will be some chance to handle high-resolution images that are not processed. It is still important to know how to correct it and how to tackle problems like aberrations. We should download the data that fits our needs. Using Landsat data as an example, the hierarchical structure of Landsat data is Collection→ Level→ Tier. In general, we choose Collection 2 + Level-2 + Tier 1.\n\n\n\n\n\nCorrection\npurposes /defination\nmethods\ninput data\noutput\nApplications\n\n\n\n\nGeometric Correction\nCorrects distortions caused by the sensor or satellites to align the image with the geographic coordinate system, ensuring spatial accuracy.\ndifferent transformation types(linear, polynomial, Helmert…)\nPixel coordinates of the original image, GCPs（Ground Control Points, Pixel coordinates of the rectified (gold standard) map\ncorrected image\nThe basis for subsequent georectification and orthorectification\n\n\nAtmospheric Correction\nRemoval of environmental attenuation:Atmospheric scattering and Topographic attenuation\nDOS（Dark object subtraction, PIFs (Psuedo-invariant Features), Py6S, FLAASH, ACORN, QUAC, ATCOR Empirical Line Correction\nradiance reflected above the surface , Atmospheric attenuation\nTop-of-atmosphere reflectance and Surface reflectance\nBiophysical parameters required and the use of spectral signatures across time and space.\n\n\nOrthorectification\nremoving distortions. making the pixels viewed at the nadir (straight down)\nCosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nradiance, Sun's zenith angle, Sun's incidence angle slope angle (from DEM), slope aspect, solar zenith, solar azimuth\ngeographically aligned and topography removed\nOrthorectification Is a subset of georectification, useful for Precise Georeferencing and High-Precision Measurement and Spatial Analysis\n\n\nRadiometric Calibration\nConverts the digital value (DN) of an image into a physical sense of radiant brightness or reflectance, eliminating the effects of sensors, light sources, etc.\nLλ = Bias + (Gain * DN)\nDN, sensor information, Solar radiation information\nCorrected image\nOften used as a first step in data pre-processing to provide a basis for subsequent atmospheric corrections, etc.\n\n\n\n\n\n\n\n\n\n3.1.2 Joining the data\nIn some cases, we need to merge the images from different regions and times to cover the study area. We had better choose the image from the same day or else we need to standardise data. In remote sensing, it is called “Mosaicking”. This involves complex arithmetic processes: histogram matching algorithm feathering and blending. But it is simple in R just needs some time.\n\nm1 &lt;- terra::mosaic(l83, l84, fun=\"mean\")\n\n\n\n3.1.3 Image Enhancement\nWe choose the appropriate data, process it, and modify it to generate the desired output. The methods help us change the image and produce the output for our purpose. The methods are as follows.\n\n\n\n\n\nEnhancement\npurposes /defination\nmethods\ninput data\nAdvantages\nApplicable scenarios\n\n\n\n\nContrast Enhancement\nImproved visualisation of the image by widening the distribution of pixel values.\nMinimum- Maximum Percentage Linear and Standard Deviation Piecewise Linear Contrast Stretch\nImages with a narrow distributions\nEnhance images contrast and details\npre-processing for subsequent classification and visual interpretation\n\n\nBand Ratioing\nUsing the ratio of reflectance of different bands to highlight specific feature characteristics\ndivision operations (like NDVI, NDBI, tasselled cap etc.)\nMulti-spectral imagery\nEmphasis on relative differences in expression of feature characteristics\nNormalized Burn Ratio, The Normalised Difference Vegetation Index, the Normalized Difference Moisture Index (NDMI)\n\n\nFiltering\nSuppressing noise or highlighting local variations through filter operations.\nLow pass or low frequency (averages the surrounding pixels)/High pass or high frequency-enhance local variations\nOriginal data\nSmooth or sharpen images; extract edge information as required\nFeature extraction, target detection\n\n\nPCA\nDimensionality reduction, removal of inter-band correlations, and extraction of most of the information in the image.\nIn R this is prcomp() from the terra package\nMulti-spectral imagery\nExtracting the main direction of change reduces the computational burden and noise reduction\nData compression, change detection, feature extraction\n\n\nTexture\nmeasuring the relationships between pixel-to-pixel, quantifying roughness to obtain feature characteristics.\nGLCM(Gray Level Co-occurrence Matrix ) second-order texture measures, third-order texture measures\nGrey-scale images or single-band data, windows\nCharacterisation of feature texture, feature classification, target identification\nLand cover classification, target detection, environmental monitoring\n\n\nFusion\nFusion of data from different sensors or different times\nPan-sharpening, Gram-Schmidt, IHS\nMulti-temporal, multi-sensor data\nenhance the details of the images\nHigh resolution data generate, changes detection, data integration",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#application",
    "href": "Wk3_Corrections.html#application",
    "title": "3  Corrections and Enhancement",
    "section": "3.2 Application",
    "text": "3.2 Application\nDue to there are few works that we need to correct by ourselves in the current stage, I will pay more attention to image enhancement. To my surprise, I have discussed a lot about ratios in the last two weeks due to my strong interest in different band groups, it is also the most simple part of enhancement in my view. So this week, I’d like to analyse the application of texture. Texture has better identification of the inner edges of the image. Firstly, I treat texture as independent method of other image enhancements. After reading relevant articles, I recognise texture is usually used with other methods. In common for identifying feature characteristics, texture usually data fusion with multi-spectral images. (Tabib Mahmoudi, Arabsaeedi, and Alavipanah 2019) It helps improve identification accuracy. Spectral recognition and texture features combined with machine learning inspection are more accurate in recognising urban objects with spectral similarity, but these texture recognitions need massive computational efforts. This method requires hand segmentation which involves subjectivity and increases processing time, may influence the layout, so the technique is not yet mature.\n\n\n\nTexture measures Source: Remote Sensing for Dummies\n\n\nTextured images are related to the use of different texture metrics, window sizes and bands. In the GLCM package in R, there are lots of texture measures. Different combinations are suitable for identifying different landscapes. How to choose these variables? Hall-Beyer (2017a) suggests using PCA identify key measurements that could be directly selected in feature recognition. Generally, the Mean is chosen as a standard measure. If edge-like features are present, measures such as Contrast (CON) and Correlation (COR) are more appropriate. For more detailed texture analysis, Entropy (ENT) can be added. (Hall-Beyer 2017a)These guidelines help me to choose suitable measures. These guidelines are by way of a categorical ranking of several texture measures by PCA, although these choices are highly universal. However, the author reached this conclusion by analysing different natural landscapes, which lack the identification of man-made landscapes, these guidelines may not be fully applied in urban environments where structures and edges are complex. What’s more, for different natural conditions such as marine and dunes, because of the special nature of their boundaries, the performance of different measures is different and should be analysed according to the specific research object.\n\n\n\nDifferent texture measures visual appearance Source:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#reflection",
    "href": "Wk3_Corrections.html#reflection",
    "title": "3  Corrections and Enhancement",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis week we learned Correction, Mosaicking, and image enhancement. We usually comprehend different methods and concepts separately during the learning process. (But the content this week is still hard for me.) In practice, for different bands and spatial resolutions, the effects of the different methods are also different, so it is necessary to combine various methods to realise the purpose of the study. For example, when doing principal component analysis (PCA) on spectral data, the subsequent eigenchannels usually represent indexes like NDVI (vegetation) mentioned in the band ratio.(Hall-Beyer 2017b) This suggests that there may be a relationship of complementarity between the different approaches. In addition, in order to get more clearer images and results, researchers often combine different sensor data and methods of analysis.\nThe enhancement method——Texture, currently applies to natural landscape identification such as forests. But I think it can also used in small-scale urban identification because Ent is sensitive to unnatural edges and can be used to identify artificial landscapes. What’s more, compared with popular Spectroscopic methods, Texture methods (e.g. GLCM) focus on the spatial pattern of the image and may reduce the band radiometric errors due to temperature variation caused by the city heat island effect. However, texture can only be used for enlarged objects due to its large computation and the edges of the city are especially complex, which limits its ability to complement other methods in many situations. I believe addressing this limitation could be an important direction for future research, particularly in enhancing the applicability of texture analysis for urban studies. Maybe can combine texture analysis with automated feature extraction techniques, which can improve the accuracy and efficiency of urban features. In specific applications, texture features might be beneficial for urban planning, by accurately identifying traffic-congested road sections based on density variations.\n\n\n\n\nHall-Beyer, Mryka. 2017a. “Practical Guidelines for Choosing GLCM Textures to Use in Landscape Classification Tasks over a Range of Moderate Spatial Scales.” International Journal of Remote Sensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\n———. 2017b. “Practical Guidelines for Choosing GLCM Textures to Use in Landscape Classification Tasks over a Range of Moderate Spatial Scales.” International Journal of Remote Sensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\nTabib Mahmoudi, Fatemeh, Alireza Arabsaeedi, and Seyed Kazem Alavipanah. 2019. “Feature-Level Fusion of Landsat 8 Data and SAR Texture Images for Urban Land Cover Classification.” Journal of the Indian Society of Remote Sensing 47 (3): 479–85. https://doi.org/10.1007/s12524-018-0914-8.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Corrections and Enhancement</span>"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#international",
    "href": "Wk4_Policy.html#international",
    "title": "Policy",
    "section": "1.1.1 International",
    "text": "1.1.1 International\nThe 2030 Agenda for Sustainable Development also mentioned climate risk reduction in its reports. It is an important part of the 17 Sustainable Development Goals (SDGs). These SDGs build on decades of work by countries and the UN.(“THE 17 GOALS | Sustainable Development,” n.d.)\nSDG11: Make cities and human settlements inclusive, safe, resilient and sustainable\nSDG9: Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\nOther historical documents and meetings also mention the challenges caused by flooding, such as the Sendai Framework for Disaster Risk Reduction, which provides guidance for disaster prevention and control, the Guidelines for Reducing Flood Losses launched, and the Hyogo Framework for Action (2005-2015).",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#metropolitan",
    "href": "Wk4_Policy.html#metropolitan",
    "title": "Policy",
    "section": "1.1.2 Metropolitan",
    "text": "1.1.2 Metropolitan\nA LIVABLE CLIMATE is also a goal In OneNYC 2050, it proposed 4 relative initiatives for building sustainable cities. It advocates strengthening communities, buildings, infrastructure, and the waterfront to be more resilient. (21) To make the city more resilient and safer. The government also collaborated with the U.S. ARMY CORPS OF ENGINEERS to reshape the shoreline of New York. The main measures are divided into three directions: Protecting the neighbourhoud and basic infrastructure, effective management measures and more accurate research and forecasting.\n\n\n\nFlood map(Source:OneNYC 2050)",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#local",
    "href": "Wk4_Policy.html#local",
    "title": "Policy",
    "section": "1.1.3 Local",
    "text": "1.1.3 Local\nAt the local level, the city will build according to the adopting flood maps which delineate the climate projections. For example, in Lower Manhattan, the city extends the shoreline to the East River, which is 20 meters above the current sea level and set up many seafront parks.\n\n\n\nLocal policy: Lower Manhattan (Source:OneNYC 2050)\n\n\nIn conclusion, current policies are already comprehensive and specific, to explore the effectiveness of these initiatives, I think needs to be made through a data approach.",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#application",
    "href": "Wk4_Policy.html#application",
    "title": "4  Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\n\n4.2.1 Data and Model\nUsually, flood hazard mapping always includes two parts: the flood models (FL) and natural catastrophe (CAT) models. () The flood models are usually based on the hydrological modelling with DEM, channel location, river discharge and Precipitation data. The catastrophe models always include Land cover data and critical infrastructure and building footprints extracted from LIDAR data. To support the flood information decision, New York has already drawn a map to inform flood planning and Response. For example, the NYC Stormwater Flood Maps (“NYS Flood Impact Decision Support System - FIDSS,” n.d.) shows the area’s potential flooding scenarios. New York City now makes flooding monitoring with the help of FloodNet Sensors Which are 87 Low-Cost Ultrasonic sensors, which bring more precision results.\n\n\n\nNYC Stormwater Flood Maps (Source: New York City Stormwater Flood Maps)\n\n\nAlthough the hydrological modelling in the local area seems to be progressively improving perfectly. Remote sensing data is still helpful in emergency response and large-scale analyses of flooding. We can get the depth and extent of the flood by Landsat series data. By computing the modified normalized difference water index (NDWI) to do water detection after floodings. (Cohen et al. 2019) We can get flooded areas by comparing it with the Land Cover Dataset. However, Landsat data may be influenced by weather so can not get continuous data. SAR sensors like Sentinel-1 have a higher resolution (10m) and can detect through clouds, so it is more commonly applied to real-time flood monitoring. The flooding analyses estimate the post-to-preflood radar cross-section (RCS) ratio and exclusion of double scatterers (DSs) in urban areas.(Mason, Dance, and Cloke 2023) We can also get the depth of the flood by analysing it in relation to the high-resolution DEM data obtained from LIDAR.\n\n\n\nLandsat flooding analysis\n\n\nThe Land Cover Dataset is important in The Social Vulnerability analyses. We can obtain large area land cover monitoring through optical remote sensing like Landsat, Sentinel-2, and MODIS. Using different indexes helps us detect different types of covering.\nNDVI: distinguishes vegetation from non-vegetation.  \n\nNDBI: extracting building area.  \n\nNDWI: extracting body of water.  \nThe DEM Dataset is very important in flooding analyses. It’s very important in remote sensing and hydrological analysis. In the local area, we often use LIDAR to get 1-5m DEM data for more precise analyses. For larger study areas like cities, we can use SAR to get DEM data to simplify the dataset for ease of computation.\n\n\n4.2.2 Workflows\nThe New York government now retrofitted our nearly 1 million buildings and invested more than $20 billion against extreme weather events.\n\n\n\nWorkflow image",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#data-and-model",
    "href": "Wk4_Policy.html#data-and-model",
    "title": "Policy",
    "section": "1.2.1 Data and Model",
    "text": "1.2.1 Data and Model\nUsually, flood hazard mapping always includes two parts: the flood models (FL) and natural catastrophe (CAT) models. () The flood models are usually based on the hydrological modelling with DEM, channel location, river discharge and Precipitation data. The catastrophe models always include Land cover data and critical infrastructure and building footprints extracted from LIDAR data. To support the flood information decision, New York has already drawn a map to inform flood planning and Response. For example, the NYC Stormwater Flood Maps () shows the area’s potential flooding scenarios. New York City now makes flooding monitoring with the help of FloodNet Sensors Which are 87 Low-Cost Ultrasonic sensors, which bring more precision results.\n\n\n\nNYC Stormwater Flood Maps (Source: New York City Stormwater Flood Maps)\n\n\nAlthough the hydrological modelling in the local area seems to be progressively improving perfectly. Remote sensing data is still helpful in emergency response and large-scale analyses of flooding. We can get the depth and extent of the flood by Landsat series data. By computing the modified normalized difference water index (NDWI) to do water detection after floodings. (Cohen et al. 2019) We can get flooded areas by comparing it with the Land Cover Dataset. However, Landsat data may be influenced by weather so can not get continuous data. SAR sensors like Sentinel-1 have a higher resolution (10m) and can detect through clouds, so it is more commonly applied to real-time flood monitoring. The flooding analyses estimate the post-to-preflood radar cross-section (RCS) ratio and exclusion of double scatterers (DSs) in urban areas.(Mason, Dance, and Cloke 2023) We can also get the depth of the flood by analysing it in relation to the high-resolution DEM data obtained from LIDAR.\n\n\n\nLandsat flooding analysis\n\n\nThe Land Cover Dataset is important in The Social Vulnerability analyses. We can obtain large area land cover monitoring through optical remote sensing like Landsat, Sentinel-2, and MODIS. Using different indexes helps us detect different types of covering.\nNDVI: distinguishes vegetation from non-vegetation.  \n\nNDBI: extracting building area.  \n\nNDWI: extracting body of water.  \nThe DEM Dataset is very important in flooding analyses. It’s very important in remote sensing and hydrological analysis. In the local area, we often use LIDAR to get 1-5m DEM data for more precise analyses. For larger study areas like cities, we can use SAR to get DEM data to simplify the dataset for ease of computation.",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#reflection",
    "href": "Wk4_Policy.html#reflection",
    "title": "4  Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nCurrent NYC Flood Maps may be plots based on hydrological data modelled through hydrological analysis. New York is a coastal city with many important rivers, the analysis will be difficult because of the different hydrological properties of sea and river water. I think using remote sensing data for analysis is simpler. Because water has the same reflective properties, and the analysis is focused on the results rather than the hydrological process. It is more suitable for large areas of study like the whole of New York City. Moreover, remote sensing data can be used to monitor the influence of flooding for a long duration and offer the changes data before and after policy implementation. A Data-Driven Approach to urban planning analyses data from different scopes with different methods leading to more efficient and accurate policy delivery. New York takes many projects to protect Lower Manhattan and plots the project region and location on the map, reflecting zoning planning, which is very specific and highly instructive.\nNew York has written financial investment and project size for extreme floods in OneNYC 2050. The planning out the development and goal of relative projects in the future. It gives good guidance for implementation. However, it does not mention the Projection of the effects of these policies, remote sensing data can provide clear changes before and after the implementation of the policy, and provide support for those projects.\n\n\n\n\nCohen, Sagy, Austin Raney, Dinuke Munasinghe, J. Derek Loftis, Andrew Molthan, Jordan Bell, Laura Rogers, et al. 2019. “The Floodwater Depth Estimation Tool (FwDET V2.0) for Improved Remote Sensing Analysis of Coastal Flooding.” Natural Hazards and Earth System Sciences 19 (9): 2053–65. https://doi.org/10.5194/nhess-19-2053-2019.\n\n\nFuleihan, Dean, Dominic Williams, Daniel A Zarrilli, and OneNYC Director. n.d. “The City of New York Mayor Bill de Blasio.”\n\n\nMason, David C., Sarah L. Dance, and Hannah L. Cloke. 2023. “Toward Improved Urban Flood Detection Using Sentinel-1: Dependence of the Ratio of Post- to Preflood Double Scattering Cross Sections on Building Orientation.” Journal of Applied Remote Sensing 17 (1): 16507. https://doi.org/10.1117/1.JRS.17.016507.\n\n\n“NYS Flood Impact Decision Support System - FIDSS.” n.d. https://sedac.ciesin.columbia.edu/mapping/nysfidss/?page=NYS-FIDSS&views=About.\n\n\n“THE 17 GOALS | Sustainable Development.” n.d. https://sdgs.un.org/goals.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#workflows",
    "href": "Wk4_Policy.html#workflows",
    "title": "Policy",
    "section": "1.2.2 Workflows",
    "text": "1.2.2 Workflows\nThe New York government now retrofitted our nearly 1 million buildings and invested more than $20 billion against extreme weather events.\n\n\n\nWorkflow image",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#summary",
    "href": "Wk4_Policy.html#summary",
    "title": "4  Policy",
    "section": "",
    "text": "4.1.1 International\nThe 2030 Agenda for Sustainable Development also mentioned climate risk reduction in its reports. It is an important part of the 17 Sustainable Development Goals (SDGs). These SDGs build on decades of work by countries and the UN.(“THE 17 GOALS | Sustainable Development,” n.d.)\nSDG11: Make cities and human settlements inclusive, safe, resilient and sustainable\nSDG9: Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\nOther historical documents and meetings also mention the challenges caused by flooding, such as the Sendai Framework for Disaster Risk Reduction, which provides guidance for disaster prevention and control, the Guidelines for Reducing Flood Losses launched, and the Hyogo Framework for Action (2005-2015).\n\n\n4.1.2 Metropolitan\nA LIVABLE CLIMATE is also a goal In OneNYC 2050, it proposed 4 relative initiatives for building sustainable cities. It advocates strengthening communities, buildings, infrastructure, and the waterfront to be more resilient. (21) To make the city more resilient and safer. The government also collaborated with the U.S. ARMY CORPS OF ENGINEERS to reshape the shoreline of New York. The main measures are divided into three directions: Protecting the neighbourhoud and basic infrastructure, effective management measures and more accurate research and forecasting.\n\n\n\nFlood map(Source:OneNYC 2050)\n\n\n\n\n4.1.3 Local\nAt the local level, the city will build according to the adopting flood maps which delineate the climate projections. For example the East Side Coastal Resiliency (ESCR) Project, in Lower Manhattan, the city extends the shoreline to the East River, which is 20 meters above the current sea level and set up many seafront parks.\n\n\n\nLocal policy: Lower Manhattan (Source:OneNYC 2050)\n\n\nIn conclusion, current policies are already comprehensive and specific, to explore the effectiveness of these initiatives, I think needs to be made through a data approach.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Policy</span>"
    ]
  },
  {
    "objectID": "Wk6_GEE.html",
    "href": "Wk6_GEE.html",
    "title": "5  An introduction to Google Earth Engine",
    "section": "",
    "text": "5.1 Summary\nGoogle Earth Engine(GEE) can access and tackle Geographic information data quickly by using a cloud computing platform. I think GEE has two main benefits.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Wk6_GEE.html#summary",
    "href": "Wk6_GEE.html#summary",
    "title": "5  An introduction to Google Earth Engine",
    "section": "",
    "text": "5.1.1 Benefits\n\nGEE is lazy computing for users compared with traditional data analysis methods like ArcGIS, R and Python. GEE data preprocessing operations, such as reprojection and uniform resolution, can be handled automatically. So, the data in GEE is analysis-ready. It helps users to focus on data analysis and application work.\nGEE can access and deal with large-scale data, especially global remote sensing data. As a cloud-based platform, it is easy for researchers to disseminate their results to others, making the project more reproducible. No need to upload local files to GitHub (which has a size limit, and most remote sensing images can’t be uploaded) to share the results as before.\n\n\n\n\n\n\n\n\n\n\n\nThis process uses a pyramid of downsampled tiles, reducing the image to multiple scales until it reaches 256 × 256 pixels per tile. Making the processing more efficient. Here, I use the image and the example of LandSat with 30m resolution to help me understand it.\n\nIn GEE, we can perform lots of processes, like reducing images, linear regression, image enhancements, etc. GEE is mainly programmed with JavaScript; compared with R, the data tackling is more simplified. The table shows the differences between GEE and R.\n\n\n\n\n\nFeature\nR (Local Computing)\nGEE (Cloud Computing)\n\n\n\n\nData Storage\nData is saved on your computer's memory or hard drive.\nData is stored on Google's servers, and your code just refers to it.\n\n\nComputation\nRuns immediately on your computer (eager evaluation).\nRuns only when needed (lazy computation).\n\n\nLooping\nYou can use for loops and apply() to process data.\nYou can't use for loops on ee objects. Instead, you need to use map().\n\n\nVisualization\nNeeds ggplot2 or tmap to draw maps.\nYou can show maps directly with Map.addLayer() on an interactive map.\n\n\nImage data\na stack of rasters\nImage collection\n\n\nData Access\nYou must download data (e.g., Landsat, Sentinel) before using it.\nYou can access data directly from Google Earth Engine’s Data Catalog (no downloading needed).\n\n\nProjection & Resolution\nYou must manually adjust projection and resolution (st_transform(), projectRaster()).\nGEE automatically handles projection and resampling.\n\n\nMachine Learning\nUses external ML libraries like randomForest and xgboost.\nHas built-in ML tools (like Random Forest), but can't use external ML libraries.\n\n\nLimits\nOnly limited by your computer’s power, no API limits.\nFree accounts have limits on computing and storage. Pro accounts are needed for more resources.\n\n\n\n\n\n\n\n\n\n5.1.2 Limitations\nGEE is used in a variety of study areas like global forest change, crop yield estimation, fire recovery, etc. because of its efficient access and computation and the wealth of data types and functions in the library. It can especially show its benefits when it comes to large-scale data or time series analyses. However, it also has limitations. 1. It is influenced by Google’s server resource allocation; Google’s server resources affect request limits, including how long they run and how many can run at the same time.. That may lead to the failure of some complicated computation. 2. It may not work well for operations involving value can be influenced by arbitrarily distant input or data not covered by the GEE library.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Wk6_GEE.html#application",
    "href": "Wk6_GEE.html#application",
    "title": "5  An introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nI have explored what influence the data from different sensors would have on the analysis of crop yield estimation. This week, I want to focus on the impact of analyses of GEE. I conclude two articles to make comparisons, both of them using a vegetation index to set up a random forest model to predict the crop yield. But one of them used GEE to analyse, the other used traditional methods.\n\nThe role of GEE in data processing\n\nChoudhary et al. Choudhary et al. (2022) using GEE to remove all errors and get similar weight to tackle the data quickly. These steps helps quickly access to multi-temporal Sentinel-2 data and reduce the time to deal with data. But GEE data tackling may ignore the unusual weather or special local terrain which may reduces the prediction accuracy. Hunt et al. Astola et al. (2019) did data pre-processing manually (like using buffer to remove gaps from data cleaning), selecting a date image with fewer clouds and use Sen2Cor processor to correct data, improved the quality of input data ,so the model performances more consistent.\n\nPerformance of random forests in GEE and non-GEE environments\n\nHunt et al. Astola et al. (2019) using different combinations of data( meteorological, terrain, and soil moisture content) to improve the RF model prediction result in wheat production. Precision of yield estimation at field level (RMSE 0.61 t/ha) is a specific estimation methods can be modified with manual feature adjustment to select model parameters and data input. This approach is more suitable for small-scale, high-precision farm management. Choudhary et al. Choudhary et al. (2022) used GEE for efficient calculation and can quickly complete comparative testing of multiple models (RF, linear regression, decision trees). Although the model accuracy is (RMSE 0.40 t/ha) lower than traditional methods. The advantage of GEE is that it is suitable for large-scale agricultural monitoring. It is easy to analyse vegetation dynamics across seasons and over long periods of time using GEE. GEE can automate data handling processes, although it limits variable screening and manual model simulations affect accuracy, but it is suitable for large scale learning.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An introduction to Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "Wk6_GEE.html#reflection",
    "href": "Wk6_GEE.html#reflection",
    "title": "5  An introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nAfter comparing the above two articles, according to the features of the plant, I think it is more appropriate to exchange the tools used by the article. Wheat is mostly grown in the plains with larger areas per farmland, which has been put into mechanised production on a large scale. So, it is more suitable for larger-scale predictions using GEE. GEE can be monitored across multiple growing seasons, providing data for large-scale crop yield estimation, supply chain regulation and reduction monitoring. Field crops such as corn and soybeans are also well-suited for GEE analysis.\nLocal calculation can use high resolution commercial remotely sensed data (like quick bird) is more suitable for rice. Because rice is a crop with small field sizes and complex growing practices (e.g. terraced planting, mixed cropping) that requires careful management. Specific local calculation can combine local climate and terrain data to classify and analyse more accurately which support the intensive farming needs such as pest and disease monitoring, soil and water conservation, etc. GEE is limited by its resolution, making it difficult to meet the accuracy needs However, high-resolution remote sensing data is expensive, now is only available using in Japan and Korea. For other rice-growing Asian countries it is hard to promote. So, GEE will help these country access to remote-sensing data with low-cost, extensive crop monitoring and food security in those place. In future, the process depends not only on data quality and computational power but also can combine with crop growth characteristics, agricultural production patterns and economic viability.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nChoudhary, K., W. Shi, Y. Dong, and R. Paringer. 2022. “Random Forest for Rice Yield Mapping and Prediction Using Sentinel-2 Data with Google Earth Engine.” Advances in Space Research 70 (8): 2443–57. https://doi.org/10.1016/j.asr.2022.06.073.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>An introduction to Google Earth Engine</span>"
    ]
  }
]