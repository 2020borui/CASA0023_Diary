[
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html",
    "href": "Wk1_Introduction_to_remote_sensing.html",
    "title": "Introduction to remote sensing",
    "section": "",
    "text": "1.1 Summary\nThis week’s learning content can be divided into two parts: The first part is the concept of remote sensing and the process of gaining the data. Especially, discussing how the interaction between Electromagnetic radiation and Earth’s surface (reflecting, absorbing and scattering) influences the data quality. There are different impacts on electromagnetic radiation with different wavelengths, so it’s important to choose suitable bands to analyse. Moreover, the weather especially the clouds will influence on capturing data. SAR can go through the clouds to reduce the impacts.\nThe second parts introduce the type of remote data, and how to simply deal with data by plotting spectral signatures. In this practical we use snap and r to deal with Landsat and Sentinel data. The main difference between remote data is from four resolutions: spatial, spectral, temporal and radiometric.\nThe steps are:\nTasseled Caps",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#summary",
    "href": "Wk1_Introduction_to_remote_sensing.html#summary",
    "title": "Introduction to remote sensing",
    "section": "",
    "text": "remote sensing process Source: Remote Sensing for Dummies\n\n\n\n\n\n\nDownloading data with less cloud cover, choosing different band combinations for different visuals\n\n\nMasking the study area and resampling the data in one spatial resolution using the nearest neighbour. Choosing down-scaling to avoid errors when calculating. The nearest neighbour is more effective and faster than bilinear or cubic convolution. But there will be abrupt changes at the boundary leading to large errors. When deciding to resample the resolution should not change too much which will influence the accuracy of the result.\n\n\nSelect POIs, and create vector data containers for different land cover.\n\n\nDraw vector, export the Geo-tiff and shapefile load the file in R studio, and extract the value of tiff by vector.\n\n\nPlotting the Spectral signatures and comparing the difference of two sensors with the same band and same land use by t-test. The value of Landsat is much greater than that of Sentinel.\n\n\n\n\n\n\n\n\n\n\n\nLandsat Spectral signatures\n\n\n\n\n\n\n\nSentinel Spectral signatures",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#applications",
    "href": "Wk1_Introduction_to_remote_sensing.html#applications",
    "title": "Introduction to remote sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nI’m interested in remote sensing in vegetation monitoring. The main difference between the two sensors Landsat and Sentinel is in the various resolutions on spatial, spectral and temporal. By comparing two articles about machine learning used in vegetation monitoring, I observed that two types of data perform differently in different tasks. Sentinel data performs more accurately in predicting by regression on a small scale, the Landsat data is more accurate in classifying vegetation types over large areas.\nIt may be due to the following reasons: Sentinel has a red edge band (B5, B6 and B7) that is more sensitive to monitoring vegetation. It also has a higher resolution of around 10M and 20M, so it has a more accurate prediction of vegetation characteristics such as trunk height for forest variables. (Astola et al. 2019) Sentinel has a 5-day return cycle, so, it captures short-term changes in vegetation well, but it will be complicated to handle large ranges of data. As a new sensor from 2015, it may be a lack of data build-up.\n\n\n\nModel accuracy for different data sources Source: Ram C. Sharma’s article\n\n\nTo my surprise, Landsat data are more accurate in studies related to the classification of vegetation types by setting a random forest model. (Sharma, Hara, and Tateishi 2017)Although Landsat has a 16-day return cycle, due to the length of time covered it has rich datasets and it has SWIR and thermal infrared bands, both of which can provide help for the study of large-scale classification. At the end of the article, the author got a more precise classification by combination of the two types of data.\nHow can these methods be applied to real life? Scientists found that near-infrared radiation can observe the health of vegetation. It is based on the principle that the health status of plants will influence the plant’s spectrum of both absorption and reflection. The U.S. Department of Agriculture uses Landsat and the U.S. Geological Survey to forecast agricultural productivity in each growing season. (Blickensdörfer et al. 2022)According to the comparison above, I think the result will be better to use Landsat data for large-scale farmland species identification, and then use Sentinel data to monitor small-scale changes in the growing season of a single crop.\n\n\n\nThe difference between Sentinel-2 and Landsat 8\n\n\nComparison Factors\nSentinel-2\nLandsat 8\n\n\n\n\nTemporal Coverage\n~73 times/year (high frequency)\n~23 times/year (low frequency)\n\n\nSpatial Resolution\n10 m (selected bands), 20 m (red edge)\n30 m (except 15 m panchromatic)\n\n\nBand Configuration\nVisible, NIR, SWIR, red edge (no thermal infrared)\nVisible, NIR, SWIR, thermal infrared\n\n\nClassification Performance\nMulti-temporal features enhance vegetation health classification\nLong-term data improves stability, versatile band coverage\n\n\nAdvantages\nSuperior for small-scale, short-term changes (e.g., vegetation health)\nSuperior for large-scale, long-term changes (e.g., vegetation types)\n\n\nApplications\nBetter for specific feature prediction\nBetter for large-scale classification",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "href": "Wk1_Introduction_to_remote_sensing.html#reflection",
    "title": "Introduction to remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThrough this week I have learnt about the principles of remote sensing and a deep understanding of the advantages and application of Sentinel-2 and Landsat 8 data. Considering that radiation is an important element in remote sensing, I am wondering how climate change affects remote sensing vegetation monitoring. With global warming and the greenhouse effect, will the increased thermal radiation in the atmosphere have impacts on remote sensing results? Will the increased plant transpiration due to warming affect the absorption of red light and the reflection of near-infrared light? Can remote sensing capture the slight changes? Whether the use of thermal infrared bands in vegetation health monitoring needs to be adapted due to global warming? These issues need to be addressed step by step in the future.\nAlthough there are massive studies about using and comparing Landsat and Sentinel-2 data on vegetation research, I am interested in how to innovate under the background of climate change. Could we build a model to predict the influence of climate on vegetation growth? Based on that we can predict how vegetation in a region or globally will be distributed over the next 50 years based on current climate change. It’s a big help to our food security and species conservation. Moreover, through this week’s studying, I also learned how to choose data with suitable resolution and choose a band which is more suitable for specific tasks. I think the ability to choose suitable data sets and methods is important in future study and learning.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nBlickensdörfer, Lukas, Marcel Schwieder, Dirk Pflugmacher, Claas Nendel, Stefan Erasmi, and Patrick Hostert. 2022. “Mapping of Crop Types and Crop Sequences with Combined Time Series of Sentinel-1, Sentinel-2 and Landsat 8 Data for Germany.” Remote Sensing of Environment 269 (February): 112831. https://doi.org/10.1016/j.rse.2021.112831.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017. “High-Resolution Vegetation Mapping in Japan by Combining Sentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine Learning and Cross-Validation Approach.” Land 6 (3): 50. https://doi.org/10.3390/land6030050.",
    "crumbs": [
      "Introduction to remote sensing"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html",
    "href": "Wk3_Corrections.html",
    "title": "Corrections and Enhancement",
    "section": "",
    "text": "1.1 Summary\nThe lecture includes two parts: Correction data and Accessing data. This is preparation for conducting data research.",
    "crumbs": [
      "Corrections and Enhancement"
    ]
  },
  {
    "objectID": "Wk4_Policy.html",
    "href": "Wk4_Policy.html",
    "title": "Policy",
    "section": "",
    "text": "1.1 Summary\nNow, we are against the challenges of a changing climate. Disaster risk reduction (DRR) and sustainable development are important for all cities worldwide. The increase in large-scale precipitation, coastal flooding and rising sea levels from climate change is a great challenge to the safety of urban residents and urban infrastructure. According to the projections from NPCC, at the end of the century, the frequency of 100-year floods will be up to 3.6%.\nNew York as a famous coastal city has hundreds of miles of waterfront and commercial harbours. It will face more emergency crises from flooding, the sea levels rise in New York are twice the global average. By the 2050s, nearly 1 million residents will be influenced by the coastal floodings, some commercial regions will be flooded without protective measures. (Fuleihan et al., n.d.)",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Astola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma\nKilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for\nForest Variable Prediction in Boreal Region.” Remote Sensing\nof Environment 223 (March): 257–73. https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nBlickensdörfer, Lukas, Marcel Schwieder, Dirk Pflugmacher, Claas Nendel,\nStefan Erasmi, and Patrick Hostert. 2022. “Mapping of Crop Types\nand Crop Sequences with Combined Time Series of Sentinel-1, Sentinel-2\nand Landsat 8 Data for Germany.” Remote Sensing of\nEnvironment 269 (February): 112831. https://doi.org/10.1016/j.rse.2021.112831.\n\n\nHall-Beyer, Mryka. 2017a. “Practical Guidelines for Choosing GLCM\nTextures to Use in Landscape Classification Tasks over a Range of\nModerate Spatial Scales.” International Journal of Remote\nSensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\n———. 2017b. “Practical Guidelines for Choosing GLCM Textures to\nUse in Landscape Classification Tasks over a Range of Moderate Spatial\nScales.” International Journal of Remote Sensing 38 (5):\n1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\nSharma, Ram, Keitarou Hara, and Ryutaro Tateishi. 2017.\n“High-Resolution Vegetation Mapping in Japan by Combining\nSentinel-2 and Landsat 8 Based Multi-Temporal Datasets Through Machine\nLearning and Cross-Validation Approach.” Land 6 (3): 50.\nhttps://doi.org/10.3390/land6030050.\n\n\nTabib Mahmoudi, Fatemeh, Alireza Arabsaeedi, and Seyed Kazem Alavipanah.\n2019. “Feature-Level Fusion of Landsat 8 Data and SAR Texture\nImages for Urban Land Cover Classification.” Journal of the\nIndian Society of Remote Sensing 47 (3): 479–85. https://doi.org/10.1007/s12524-018-0914-8.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Personal Introduction\nMy name is Borui. I am from Beijing. I did my undergraduate degree at China Agricultural University and majored in Landscape Architecture. During that time, I became interested in landscape design, which covered topics such as food security, climate change, urban segregation, etc. This is my portfolio from undergrad. I am also interested in the challenges that cities will face due to climate change, such as flooding, and chose a related topic for my undergraduate final project.\nNow, I am studying MSc in spatial data science. I hope to be able to analyse the problems in urban space using data sciences and to improve my quantitative analysis and coding skills.\nI took this module Remotely Sensing Cities and Environments to learn more about environmental hazards arising from a changing climate. Through learning and operationalising remotely sensed Earth observation data, I hope I can provide effective recommendations for today’s cities or urban planning.\nThis diary will record my learning process throughout the module. It includes a summary of knowledge from each lesson, practical application and personal reflective thinking. I hope to be able to show what I have learnt from this module in this way.",
    "crumbs": [
      "Personal Introduction"
    ]
  },
  {
    "objectID": "Wk2_Presentation.html",
    "href": "Wk2_Presentation.html",
    "title": "Xaringan Presentation",
    "section": "",
    "text": "This week we tried to use markdown tools like Xaringan and Quarto to show our idea on the website with code. How to adjust the templates and hide the code blocks was difficult for me during the learning process. Creating presentations through code gives the presentation file greater presentational reproducibility and flexibility. Although the process of learning is difficult, it can give me a strong sense of achievement. Here is a presentation that introduces the functions of the Sentinel-2, created through the Xaringan.\n\n\n\n\n\n\n\n\nView Full PowerPoint",
    "crumbs": [
      "Xaringan Presentation"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#summary",
    "href": "Wk3_Corrections.html#summary",
    "title": "Corrections and Enhancement",
    "section": "",
    "text": "1.1.1 correction\nThe correction makes the raw remote-sensing data become “Analysis Ready Data”(ARD). In this lecture, we mainly learn four kinds of correction: Geometric Correction, Atmospheric Correction, Orthorectification, and Radiometric Correction. I try to figure out the connection between them to have a better understanding. It seems like the Radiometric correction and atmospheric correction are the most common correction steps in remote sensing data processing, and are usually required for every image. Geometric Correction and Orthorectification are commonly used processing scenarios where spatial aberrations exist or where accurate spatial analysis is required, not every data is needed. The following table will introduce details about different corrections. Regression is important in correction methods.\nSurface reflectance is the result of radiative and atmospheric corrections. In practice, we get the reflectance from DN (level 1) through DOS methods. Nowadays there are many ways to get processed data like Landsat8 (level 2-surface reflectance). This data has been atmospherically corrected. Saves a lot of work. But in the future, there will be some chance to handle high-resolution images that are not processed. It is still important to know how to correct it and how to tackle problems like aberrations. We should download the data that fits our needs. Using Landsat data as an example, the hierarchical structure of Landsat data is Collection→ Level→ Tier. In general, we choose Collection 2 + Level-2 + Tier 1.\n\n\n\n\n\nCorrection\npurposes /defination\nmethods\ninput data\noutput\nApplications\n\n\n\n\nGeometric Correction\nCorrects distortions caused by the sensor or satellites to align the image with the geographic coordinate system, ensuring spatial accuracy.\ndifferent transformation types(linear, polynomial, Helmert…)\nPixel coordinates of the original image, GCPs（Ground Control Points, Pixel coordinates of the rectified (gold standard) map\ncorrected image\nThe basis for subsequent georectification and orthorectification\n\n\nAtmospheric Correction\nRemoval of environmental attenuation:Atmospheric scattering and Topographic attenuation\nDOS（Dark object subtraction, PIFs (Psuedo-invariant Features), Py6S, FLAASH, ACORN, QUAC, ATCOR Empirical Line Correction\nradiance reflected above the surface , Atmospheric attenuation\nTop-of-atmosphere reflectance and Surface reflectance\nBiophysical parameters required and the use of spectral signatures across time and space.\n\n\nOrthorectification\nremoving distortions. making the pixels viewed at the nadir (straight down)\nCosine correction, Minnaert correction, Statistical Empirical correction, C Correction (advancing the Cosine)\nradiance, Sun's zenith angle, Sun's incidence angle slope angle (from DEM), slope aspect, solar zenith, solar azimuth\ngeographically aligned and topography removed\nOrthorectification Is a subset of georectification, useful for Precise Georeferencing and High-Precision Measurement and Spatial Analysis\n\n\nRadiometric Calibration\nConverts the digital value (DN) of an image into a physical sense of radiant brightness or reflectance, eliminating the effects of sensors, light sources, etc.\nLλ = Bias + (Gain * DN)\nDN, sensor information, Solar radiation information\nCorrected image\nOften used as a first step in data pre-processing to provide a basis for subsequent atmospheric corrections, etc.\n\n\n\n\n\n\n\n\n\n1.1.2 Joining the data\nIn some cases, we need to merge the images from different regions and times to cover the study area. We had better choose the image from the same day or else we need to standardise data. In remote sensing, it is called “Mosaicking”. This involves complex arithmetic processes: histogram matching algorithm feathering and blending. But it is simple in R just needs some time.\n\nm1 &lt;- terra::mosaic(l83, l84, fun=\"mean\")\n\n\n\n1.1.3 Image Enhancement\nWe choose the appropriate data, process it, and modify it to generate the desired output. The methods help us change the image and produce the output for our purpose. The methods are as follows.\n\n\n\n\n\nEnhancement\npurposes /defination\nmethods\ninput data\nAdvantages\nApplicable scenarios\n\n\n\n\nContrast Enhancement\nImproved visualisation of the image by widening the distribution of pixel values.\nMinimum- Maximum Percentage Linear and Standard Deviation Piecewise Linear Contrast Stretch\nImages with a narrow distributions\nEnhance images contrast and details\npre-processing for subsequent classification and visual interpretation\n\n\nBand Ratioing\nUsing the ratio of reflectance of different bands to highlight specific feature characteristics\ndivision operations (like NDVI, NDBI, tasselled cap etc.)\nMulti-spectral imagery\nEmphasis on relative differences in expression of feature characteristics\nNormalized Burn Ratio, The Normalised Difference Vegetation Index, the Normalized Difference Moisture Index (NDMI)\n\n\nFiltering\nSuppressing noise or highlighting local variations through filter operations.\nLow pass or low frequency (averages the surrounding pixels)/High pass or high frequency-enhance local variations\nOriginal data\nSmooth or sharpen images; extract edge information as required\nFeature extraction, target detection\n\n\nPCA\nDimensionality reduction, removal of inter-band correlations, and extraction of most of the information in the image.\nIn R this is prcomp() from the terra package\nMulti-spectral imagery\nExtracting the main direction of change reduces the computational burden and noise reduction\nData compression, change detection, feature extraction\n\n\nTexture\nmeasuring the relationships between pixel-to-pixel, quantifying roughness to obtain feature characteristics.\nGLCM(Gray Level Co-occurrence Matrix ) second-order texture measures, third-order texture measures\nGrey-scale images or single-band data, windows\nCharacterisation of feature texture, feature classification, target identification\nLand cover classification, target detection, environmental monitoring\n\n\nFusion\nFusion of data from different sensors or different times\nPan-sharpening, Gram-Schmidt, IHS\nMulti-temporal, multi-sensor data\nenhance the details of the images\nHigh resolution data generate, changes detection, data integration",
    "crumbs": [
      "Corrections and Enhancement"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#application",
    "href": "Wk3_Corrections.html#application",
    "title": "Corrections and Enhancement",
    "section": "1.2 Application",
    "text": "1.2 Application\nDue to there are few works that we need to correct by ourselves in the current stage, I will pay more attention to image enhancement. To my surprise, I have discussed a lot about ratios in the last two weeks due to my strong interest in different band groups, it is also the most simple part of enhancement in my view. So this week, I’d like to analyse the application of texture. Texture has better identification of the inner edges of the image. Firstly, I treat texture as independent of other image enhancements. After reading relevant articles, I recognise texture is usually used with other methods. In common for identifying feature characteristics, texture usually data fusion with multi-spectral images. (Tabib Mahmoudi, Arabsaeedi, and Alavipanah 2019) It Helps improve identification accuracy. Textured images are related to the use of different texture metrics, window sizes and bands. In the GLCM package in R, there are lots of texture measures. Different combinations are suitable for identifying different landscapes.\n\n\n\nTexture measures Source: Remote Sensing for Dummies\n\n\nHow to choose these variables? Hall-Beyer uses PCA to identify key measures that can be directly selected in feature recognition. Generally choosing Mean, in the case of containing edge-like features, choosing CON.COR, for more detailed texture studies, add Ent. (Hall-Beyer 2017a)These guidelines help me to choose suitable measures. Texture current applies to natural landscape identification such as forests. (texture?-) But I think it can also used in small-scale urban identification because Ent is sensitive to unnatural edges and can be used to identify artificial landscapes. What’s more, compared with popular Spectroscopic methods, Texture methods (e.g. GLCM) focus on the spatial pattern of the image and may reduce the band radiometric errors due to temperature variation caused by the city heat island effect. But texture can only be used for enlarged objects due to its large computation, which makes it a big limitation to assist other methods in many cases. Especially, The edges of the city are very complex.\n\n\n\nDifferent texture measures visual appearance Source:",
    "crumbs": [
      "Corrections and Enhancement"
    ]
  },
  {
    "objectID": "Wk3_Corrections.html#reflection",
    "href": "Wk3_Corrections.html#reflection",
    "title": "Corrections and Enhancement",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThis week we learned Correction, Mosaicking, and image enhancement. We usually comprehend different methods and concepts separately during the learning process. (But the content this week is still hard for me.) But in practice, for different bands and spatial resolutions, the effects of the different methods are also different, so it is necessary to combine various methods. For example, when doing principal component analysis (PCA) on spectral data, the subsequent eigenchannels usually represent indexes like NDVI (vegetation) mentioned in the band ratio.(Hall-Beyer 2017b) This suggests that there may be a relationship of complementarity between the different approaches. In addition, in order to get more clearer images and results, researchers often combine different sensor data and methods of analysis.\nI realize that innovations don’t have to be just coming up with new approaches. In many cases, integrating, and regrouping existing methods, and applying them to new objects is also an important innovative way for research. That’s why although the data we deal with is already corrected we still need to learn the details about corrections. Researchers need to have an in-depth understanding of the data source and character and the scenarios for the application of various data correction and processing methods. Only based on a full knowledge of these can reasonable analyses and judgments be made. That’s why this week we need to Learning the formulas and principles of the method of correction.\n\n\n\n\nHall-Beyer, Mryka. 2017a. “Practical Guidelines for Choosing GLCM Textures to Use in Landscape Classification Tasks over a Range of Moderate Spatial Scales.” International Journal of Remote Sensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\n———. 2017b. “Practical Guidelines for Choosing GLCM Textures to Use in Landscape Classification Tasks over a Range of Moderate Spatial Scales.” International Journal of Remote Sensing 38 (5): 1312–38. https://doi.org/10.1080/01431161.2016.1278314.\n\n\nTabib Mahmoudi, Fatemeh, Alireza Arabsaeedi, and Seyed Kazem Alavipanah. 2019. “Feature-Level Fusion of Landsat 8 Data and SAR Texture Images for Urban Land Cover Classification.” Journal of the Indian Society of Remote Sensing 47 (3): 479–85. https://doi.org/10.1007/s12524-018-0914-8.",
    "crumbs": [
      "Corrections and Enhancement"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#international",
    "href": "Wk4_Policy.html#international",
    "title": "Policy",
    "section": "1.1.1 International",
    "text": "1.1.1 International\nThe 2030 Agenda for Sustainable Development also mentioned climate risk reduction in its reports. It is an important part of the 17 Sustainable Development Goals (SDGs). These SDGs build on decades of work by countries and the UN.(“THE 17 GOALS | Sustainable Development,” n.d.)\nSDG11: Make cities and human settlements inclusive, safe, resilient and sustainable\nSDG9: Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\nOther historical documents and meetings also mention the challenges caused by flooding, such as the Sendai Framework for Disaster Risk Reduction, which provides guidance for disaster prevention and control, the Guidelines for Reducing Flood Losses launched, and the Hyogo Framework for Action (2005-2015).",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#metropolitan",
    "href": "Wk4_Policy.html#metropolitan",
    "title": "Policy",
    "section": "1.1.2 Metropolitan",
    "text": "1.1.2 Metropolitan\nA LIVABLE CLIMATE is also a goal In OneNYC 2050, it proposed 4 relative initiatives for building sustainable cities. It advocates strengthening communities, buildings, infrastructure, and the waterfront to be more resilient. (21) To make the city more resilient and safer. The government also collaborated with the U.S. ARMY CORPS OF ENGINEERS to reshape the shoreline of New York. The main measures are divided into three directions: Protecting the neighbourhoud and basic infrastructure, effective management measures and more accurate research and forecasting.\n\n\n\nFlood map(Source:OneNYC 2050)",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#local",
    "href": "Wk4_Policy.html#local",
    "title": "Policy",
    "section": "1.1.3 Local",
    "text": "1.1.3 Local\nAt the local level, the city will build according to the adopting flood maps which delineate the climate projections. For example, in Lower Manhattan, the city extends the shoreline to the East River, which is 20 meters above the current sea level and set up many seafront parks.\n\n\n\nLocal policy: Lower Manhattan (Source:OneNYC 2050)\n\n\nIn conclusion, current policies are already comprehensive and specific, to explore the effectiveness of these initiatives, I think needs to be made through a data approach.",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#application",
    "href": "Wk4_Policy.html#application",
    "title": "Policy",
    "section": "1.2 Application",
    "text": "1.2 Application",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#data-and-model",
    "href": "Wk4_Policy.html#data-and-model",
    "title": "Policy",
    "section": "1.2.1 Data and Model",
    "text": "1.2.1 Data and Model\nUsually, flood hazard mapping always includes two parts: the flood models (FL) and natural catastrophe (CAT) models. () The flood models are usually based on the hydrological modelling with DEM, channel location, river discharge and Precipitation data. The catastrophe models always include Land cover data and critical infrastructure and building footprints extracted from LIDAR data. To support the flood information decision, New York has already drawn a map to inform flood planning and Response. For example, the NYC Stormwater Flood Maps () shows the area’s potential flooding scenarios. New York City now makes flooding monitoring with the help of FloodNet Sensors Which are 87 Low-Cost Ultrasonic sensors, which bring more precision results.\n\n\n\nNYC Stormwater Flood Maps (Source: New York City Stormwater Flood Maps)\n\n\nAlthough the hydrological modelling in the local area seems to be progressively improving perfectly. Remote sensing data is still helpful in emergency response and large-scale analyses of flooding. We can get the depth and extent of the flood by Landsat series data. By computing the modified normalized difference water index (NDWI) to do water detection after floodings. (Cohen et al. 2019) We can get flooded areas by comparing it with the Land Cover Dataset. However, Landsat data may be influenced by weather so can not get continuous data. SAR sensors like Sentinel-1 have a higher resolution (10m) and can detect through clouds, so it is more commonly applied to real-time flood monitoring. The flooding analyses estimate the post-to-preflood radar cross-section (RCS) ratio and exclusion of double scatterers (DSs) in urban areas.(Mason, Dance, and Cloke 2023) We can also get the depth of the flood by analysing it in relation to the high-resolution DEM data obtained from LIDAR.\n\n\n\nLandsat flooding analysis\n\n\nThe Land Cover Dataset is important in The Social Vulnerability analyses. We can obtain large area land cover monitoring through optical remote sensing like Landsat, Sentinel-2, and MODIS. Using different indexes helps us detect different types of covering.\nNDVI: distinguishes vegetation from non-vegetation.  \n\nNDBI: extracting building area.  \n\nNDWI: extracting body of water.  \nThe DEM Dataset is very important in flooding analyses. It’s very important in remote sensing and hydrological analysis. In the local area, we often use LIDAR to get 1-5m DEM data for more precise analyses. For larger study areas like cities, we can use SAR to get DEM data to simplify the dataset for ease of computation.",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#reflection",
    "href": "Wk4_Policy.html#reflection",
    "title": "Policy",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nCurrent NYC Flood Maps may be plots based on hydrological data modelled through hydrological analysis. New York is a coastal city with many important rivers, the analysis will be difficult because of the different hydrological properties of sea and river water. I think using remote sensing data for analysis is simpler. Because water has the same reflective properties, and the analysis is focused on the results rather than the hydrological process. It is more suitable for large areas of study like the whole of New York City. Moreover, remote sensing data can be used to monitor the influence of flooding for a long duration and offer the changes data before and after policy implementation. A Data-Driven Approach to urban planning analyses data from different scopes with different methods leading to more efficient and accurate policy delivery. New York takes many projects to protect Lower Manhattan and plots the project region and location on the map, reflecting zoning planning, which is very specific and highly instructive.\nNew York has written financial investment and project size for extreme floods in OneNYC 2050. The planning out the development and goal of relative projects in the future. It gives good guidance for implementation. However, it does not mention the Projection of the effects of these policies, remote sensing data can provide clear changes before and after the implementation of the policy, and provide support for those projects.\n\n\n\n\nCohen, Sagy, Austin Raney, Dinuke Munasinghe, J. Derek Loftis, Andrew Molthan, Jordan Bell, Laura Rogers, et al. 2019. “The Floodwater Depth Estimation Tool (FwDET V2.0) for Improved Remote Sensing Analysis of Coastal Flooding.” Natural Hazards and Earth System Sciences 19 (9): 2053–65. https://doi.org/10.5194/nhess-19-2053-2019.\n\n\nFuleihan, Dean, Dominic Williams, Daniel A Zarrilli, and OneNYC Director. n.d. “The City of New York Mayor Bill de Blasio.”\n\n\nMason, David C., Sarah L. Dance, and Hannah L. Cloke. 2023. “Toward Improved Urban Flood Detection Using Sentinel-1: Dependence of the Ratio of Post- to Preflood Double Scattering Cross Sections on Building Orientation.” Journal of Applied Remote Sensing 17 (1): 16507. https://doi.org/10.1117/1.JRS.17.016507.\n\n\n“THE 17 GOALS | Sustainable Development.” n.d. https://sdgs.un.org/goals.",
    "crumbs": [
      "Policy"
    ]
  },
  {
    "objectID": "Wk4_Policy.html#workflows",
    "href": "Wk4_Policy.html#workflows",
    "title": "Policy",
    "section": "1.2.2 Workflows",
    "text": "1.2.2 Workflows\nThe New York government now retrofitted our nearly 1 million buildings and invested more than $20 billion against extreme weather events.\n\n\n\nWorkflow image",
    "crumbs": [
      "Policy"
    ]
  }
]