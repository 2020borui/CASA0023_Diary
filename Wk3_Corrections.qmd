# Corrections and Enhancement

## Summary

The lecture includes two parts: Correction data and Accessing data. This is preparation for conducting data research.

### Correction

The correction makes the raw remote-sensing data become "Analysis Ready Data"(ARD). In this lecture, we mainly learn four kinds of correction: Geometric Correction, Atmospheric Correction, Orthorectification, and Radiometric Correction. I try to figure out the connection between them to have a better understanding. It seems like the Radiometric correction and atmospheric correction are the most common correction steps in remote sensing data processing, and are usually required for every image. Geometric Correction and Orthorectification are commonly used processing scenarios where spatial aberrations exist or where accurate spatial analysis is required, not every data is needed. The following table will introduce details about different corrections. Regression is important in correction methods.

Surface reflectance is the result of radiative and atmospheric corrections. In practice, we get the reflectance from DN (level 1) through DOS methods. Nowadays there are many ways to get processed data like Landsat8 (level 2-surface reflectance). This data has been atmospherically corrected. Saves a lot of work. But in the future, there will be some chance to handle high-resolution images that are not processed. It is still important to know how to correct it and how to tackle problems like aberrations. We should download the data that fits our needs. Using Landsat data as an example, the hierarchical structure of Landsat data is Collection→ Level→ Tier. In general, we choose Collection 2 + Level-2 + Tier 1.

```{r echo=FALSE,warning=FALSE, message=FALSE,escape = FALSE}
library(dplyr)
library(tidyverse)
library(kableExtra)
library(readr)
library(here)
library(knitr)
library(kableExtra)
library(readxl)
library(fs)

#read in data
read_excel(here("tables", "correction.xlsx"))%>%
  # booktab = T gives us a pretty APA-ish table
  knitr::kable(booktabs = TRUE, format = "html")%>% 
  kable_styling(position = "center",fixed_thead = TRUE, latex_options = "scale_down")%>%
  # any specifc row changes you want
    row_spec(.,
  row=0,
  bold = TRUE)
```

### Joining the data

In some cases, we need to merge the images from different regions and times to cover the study area. We had better choose the image from the same day or else we need to standardise data. In remote sensing, it is called "Mosaicking". This involves complex arithmetic processes: histogram matching algorithm feathering and blending. But it is simple in R just needs some time.

```{r eval=FALSE}
m1 <- terra::mosaic(l83, l84, fun="mean")
```

### Image Enhancement

We choose the appropriate data, process it, and modify it to generate the desired output. The methods help us change the image and produce the output for our purpose. The methods are as follows.

```{r echo=FALSE,warning=FALSE, message=FALSE,escape = FALSE}
library(dplyr)
library(tidyverse)
library(kableExtra)
library(readr)
library(here)
library(knitr)
library(kableExtra)
library(readxl)
library(fs)

#read in data
read_excel(here("tables", "enhancement.xlsx")) %>%
  knitr::kable(booktabs = TRUE,format = "html") %>%
  kable_styling(position = "center", fixed_thead = TRUE, latex_options = "scale_down") %>%
  row_spec(0, bold = TRUE)
```

## Application

Due to there are few works that we need to correct by ourselves in the current stage, I will pay more attention to image enhancement. To my surprise, I have discussed a lot about ratios in the last two weeks due to my strong interest in different band groups, it is also the most simple part of enhancement in my view. So this week, I’d like to analyse the application of texture. Texture has better identification of the inner edges of the image. Firstly, I treat texture as independent method of other image enhancements. After reading relevant articles, I recognise texture is usually used with other methods. In common for identifying feature characteristics, texture usually data fusion with multi-spectral images. [@tabibmahmoudi2019] It helps improve identification accuracy. Spectral recognition and texture features combined with machine learning inspection are more accurate in recognising urban objects with spectral similarity, but these texture recognitions need massive computational efforts. This method requires hand segmentation which involves subjectivity and increases processing time, may influence the layout, so the technique is not yet mature.

![Texture measures Source: Remote Sensing for Dummies](img/Texture_Analysis.png){#fig1 fig.align="center" fig-align="center" width="500"}

Textured images are related to the use of different texture metrics, window sizes and bands. In the GLCM package in R, there are lots of texture measures. Different combinations are suitable for identifying different landscapes. How to choose these variables? Hall-Beyer (2017a) suggests using PCA identify key measurements that could be directly selected in feature recognition. Generally, the Mean is chosen as a standard measure. If edge-like features are present, measures such as Contrast (CON) and Correlation (COR) are more appropriate. For more detailed texture analysis, Entropy (ENT) can be added. [@hall-beyer2017]These guidelines help me to choose suitable measures. These guidelines are by way of a categorical ranking of several texture measures by PCA, although these choices are highly universal. However, the author reached this conclusion by analysing different natural landscapes, which lack the identification of man-made landscapes, these guidelines may not be fully applied in urban environments where structures and edges are complex. What’s more, for different natural conditions such as marine and dunes, because of the special nature of their boundaries, the performance of different measures is different and should be analysed according to the specific research object.

![Different texture measures visual appearance Source:](img/texture.png){fig.align="center" fig-align="center" width="500"}

## Reflection

This week we learned Correction, Mosaicking, and image enhancement. We usually comprehend different methods and concepts separately during the learning process. (But the content this week is still hard for me.) In practice, for different bands and spatial resolutions, the effects of the different methods are also different, so it is necessary to combine various methods to realise the purpose of the study. For example, when doing principal component analysis (PCA) on spectral data, the subsequent eigenchannels usually represent indexes like NDVI (vegetation) mentioned in the band ratio.[@hall-beyer2017a] This suggests that there may be a relationship of complementarity between the different approaches. In addition, in order to get more clearer images and results, researchers often combine different sensor data and methods of analysis.

The enhancement method——Texture, currently applies to natural landscape identification such as forests. But I think it can also used in small-scale urban identification because Ent is sensitive to unnatural edges and can be used to identify artificial landscapes. What’s more, compared with popular Spectroscopic methods, Texture methods (e.g. GLCM) focus on the spatial pattern of the image and may reduce the band radiometric errors due to temperature variation caused by the city heat island effect. However, texture can only be used for enlarged objects due to its large computation and the edges of the city are especially complex, which limits its ability to complement other methods in many situations. I believe addressing this limitation could be an important direction for future research, particularly in enhancing the applicability of texture analysis for urban studies. Maybe can combine texture analysis with automated feature extraction techniques, which can improve the accuracy and efficiency of urban features. In specific applications, texture features might be beneficial for urban planning, by accurately identifying traffic-congested road sections based on density variations.
